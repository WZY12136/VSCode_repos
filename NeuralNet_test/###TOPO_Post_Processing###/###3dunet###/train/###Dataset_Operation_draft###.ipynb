{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Jupyter_file/topdata/top_dataset/data\\\\topdata_1_data.npy', '../Jupyter_file/topdata/top_dataset/data\\\\topdata_2_data.npy', '../Jupyter_file/topdata/top_dataset/data\\\\topdata_3_data.npy']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "data_path = '../Jupyter_file/topdata/top_dataset/'\n",
    "data_list = glob.glob(os.path.join(data_path,'data/*.npy'))\n",
    "print(data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__——————————————————制作数据集实验——————————————————__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据个数： 3\n",
      "image: torch.Size([1, 20, 40, 40])\n",
      "label: torch.Size([1, 20, 40, 40])\n",
      "image: torch.Size([1, 60, 60, 4])\n",
      "label: torch.Size([1, 60, 60, 4])\n",
      "image: torch.Size([1, 15, 90, 15])\n",
      "label: torch.Size([1, 15, 90, 15])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "class test1(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path     #输入存储数据集的文件夹的路径\n",
    "        self.data_path = glob.glob(os.path.join(self.path,'data_1/*.npy'))  #读取数据集文件夹\"data\"中所有格式为.npy的文件\n",
    "    def __getitem__(self, index):#用于通过键值对的方式访问属性\n",
    "        self.data = self.data_path[index]\n",
    "        #print(self.data)     #生成键值对访问index\n",
    "        self.label = self.data.replace('data_1','label')\n",
    "        #print('label:',self.label)\n",
    "        image = np.load(self.data) \n",
    "        label = np.load(self.label)           #按照上一步生成的index依次读取.py文件数据，生成数据集\n",
    "        return image, label                            \n",
    "        #return self.data_list[index]  #生成数据文件地址键值对\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)               \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    isbi_dataset = test1('../Jupyter_file/top_original_files/topfiles/')\n",
    "    print(\"数据个数：\", len(isbi_dataset))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                               batch_size=1, \n",
    "                                               shuffle=True)\n",
    "    for image, label in train_loader:\n",
    "        print('image:',image.shape)\n",
    "        print('label:',label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../Jupyter_file/topdata/top_dataset/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      6\u001b[0m data_list \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path,\u001b[39m'\u001b[39m\u001b[39mdata/*.npy\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(data_list)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch_cpu\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39m(os_fspath(file), \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "data_path = '../Jupyter_file/topdata/top_dataset/'\n",
    "data_list = glob.glob(os.path.join(data_path,'data/*.npy'))\n",
    "image = np.load(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__自制数据集时所参考的代码__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据个数： 30\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n",
      "image: torch.Size([2, 1, 512, 512])\n",
      "label: torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ISBI_Loader(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        # 初始化函数，读取所有data_path下的图片\n",
    "        self.data_path = data_path\n",
    "        self.imgs_path = glob.glob(os.path.join(data_path, 'image/*.png'))\n",
    "\n",
    "    def augment(self, image, flipCode):\n",
    "        # 使用cv2.flip进行数据增强，filpCode为1水平翻转，0垂直翻转，-1水平+垂直翻转\n",
    "        flip = cv2.flip(image, flipCode)\n",
    "        return flip\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # 根据index读取图片\n",
    "        image_path = self.imgs_path[index]\n",
    "        # 根据image_path生成label_path\n",
    "        label_path = image_path.replace('image', 'label')\n",
    "        # 读取训练图片和标签图片\n",
    "        image = cv2.imread(image_path)\n",
    "        label = cv2.imread(label_path)\n",
    "        # 将数据转为单通道的图片\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "        label = label.reshape(1, label.shape[0], label.shape[1])\n",
    "        # 处理标签，将像素值为255的改为1\n",
    "        if label.max() > 1:\n",
    "            label = label / 255\n",
    "        # 随机进行数据增强，为2时不做处理\n",
    "        flipCode = random.choice([-1, 0, 1, 2])\n",
    "        if flipCode != 2:\n",
    "            image = self.augment(image, flipCode)\n",
    "            label = self.augment(label, flipCode)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回训练集大小\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    isbi_dataset = ISBI_Loader(\"../Jupyter_file/data/train/\")\n",
    "    print(\"数据个数：\", len(isbi_dataset))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                               batch_size=2, \n",
    "                                               shuffle=True)\n",
    "    for image, label in train_loader:\n",
    "        print('image:',image.shape)\n",
    "        print('label:',label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15, 90, 15])\n",
      "tensor([[[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.0476e-73, 5.1800e-75, 1.0568e-81,  ..., 1.0568e-81,\n",
      "           5.1800e-75, 9.0476e-73],\n",
      "          [1.2468e-70, 2.0391e-73, 5.0028e-83,  ..., 5.0028e-83,\n",
      "           2.0391e-73, 1.2468e-70],\n",
      "          [1.1405e-72, 2.5827e-78, 1.6137e-91,  ..., 1.6137e-91,\n",
      "           2.5827e-78, 1.1405e-72],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.6240e-72, 1.5953e-74, 1.3078e-79,  ..., 1.3078e-79,\n",
      "           1.5953e-74, 1.6240e-72],\n",
      "          [1.0783e-70, 4.2400e-73, 5.5192e-81,  ..., 5.5192e-81,\n",
      "           4.2400e-73, 1.0783e-70],\n",
      "          [2.2291e-73, 1.0160e-78, 5.7987e-91,  ..., 5.7987e-91,\n",
      "           1.0160e-78, 2.2291e-73],\n",
      "          ...,\n",
      "          [2.4665e-23, 2.3994e-06, 4.5977e-07,  ..., 4.5977e-07,\n",
      "           2.3994e-06, 2.4665e-23],\n",
      "          [9.0112e-01, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 9.0112e-01],\n",
      "          [1.5479e-12, 5.6809e-01, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           5.6809e-01, 1.5479e-12]],\n",
      "\n",
      "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          ...,\n",
      "          [9.9464e-52, 7.0053e-15, 4.1784e-08,  ..., 4.1784e-08,\n",
      "           7.0053e-15, 9.9464e-52],\n",
      "          [4.9810e-14, 6.7501e-02, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           6.7501e-02, 4.9810e-14],\n",
      "          [1.0000e+00, 6.3534e-01, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           6.3534e-01, 1.0000e+00]],\n",
      "\n",
      "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 1.0000e+00],\n",
      "          ...,\n",
      "          [5.9131e-28, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           1.0000e+00, 5.9131e-28],\n",
      "          [4.4882e-13, 8.0429e-01, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           8.0429e-01, 4.4882e-13],\n",
      "          [1.0000e+00, 4.8852e-01, 1.0000e+00,  ..., 1.0000e+00,\n",
      "           4.8852e-01, 1.0000e+00]]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = np.load('../Jupyter_file/top_original_files/topfiles/data/0.npy')\n",
    "data = data[np.newaxis,:,:,:]\n",
    "tensor_data = torch.from_numpy(data) \n",
    "print(tensor_data.shape)\n",
    "print(tensor_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87d9cb3f07980ad2e9562b13ebde6b20fd86664a0df0e498c84894ee800c6d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
