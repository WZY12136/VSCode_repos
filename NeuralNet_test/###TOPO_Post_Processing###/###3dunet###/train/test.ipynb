{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class Generate_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data_path = glob.glob\\\n",
    "            (os.path.join(path,'input/*.npy'))  #读取data文件夹下所有.npy格式文件\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data_path[index]\n",
    "        data = np.load(data_path)      #读取输入数据\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        \n",
    "        label_path = data_path.replace('input', 'label')\n",
    "        label = np.load(label_path)    #读取标签数据\n",
    "        tensor_label = torch.from_numpy(label)\n",
    "\n",
    "        return tensor_data, tensor_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "# if __name__ == '__main__':\n",
    "#     dataset = Generate_Dataset('./dataset(05.09)/')\n",
    "    \n",
    "#     train_size = int(len(dataset) * 0.9)\n",
    "#     validate_size = int(len(dataset) - train_size)\n",
    "#     train_dataset, validate_dataset = torch.utils.data\\\n",
    "#                 .random_split(dataset, [train_size, validate_size])\n",
    "\n",
    "#     #print(\"读入数据个数为：\", len(top_dataset))\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#     validate_loader = DataLoader(validate_dataset, batch_size=1, shuffle=True)\n",
    "#     t = 0\n",
    "#     for train, label in train_loader:\n",
    "#         t += 1\n",
    "#         # print(train.shape)\n",
    "#         # print(label.shape)\n",
    "#     # print('共有',t,'个训练集')\n",
    "    \n",
    "#     n = 0\n",
    "#     for validate, label in validate_loader:\n",
    "#         n += 1\n",
    "#         # print(validate.shape)\n",
    "#         # print(label.shape)\n",
    "#     # print('共有',n,'个训练集')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_path = \"./dataset(05.09)/\"\n",
    "def dataset_split(data_path, batch_size):\n",
    "    dataset = Generate_Dataset(data_path)\n",
    "    print(len(dataset))\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    validate_size = int(len(dataset) - train_size)\n",
    "    train_dataset, validate_dataset = torch.utils.data.random_split(dataset, \\\n",
    "        [train_size, validate_size])\n",
    "    print(train_dataset.shape)\n",
    "    \n",
    "    # train_dataset = np.squeeze(train_dataset)\n",
    "\n",
    "    # for i in range(len(train_dataset)):\n",
    "    #     print(train_dataset[i].shape)\n",
    "    \n",
    "test = dataset_split(data_path, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "label_array = []\n",
    "\n",
    "dataindex = './dataset(05.09)/label/'\n",
    "for t in range(len(glob.glob(os.path.join(dataindex, '*.npy')))):\n",
    "    data = np.load(os.path.join(dataindex, str(t)+'.npy'))\n",
    "    # print(data.shape)\n",
    "    data = np.squeeze(data)\n",
    "    # print(data.shape)\n",
    "    if np.all(data == 0):\n",
    "        label_array.append(0)\n",
    "    else:\n",
    "        label_array.append(t)\n",
    "print(len(label_array))\n",
    "# print(label_array)\n",
    "\n",
    "label_array = np.array(label_array).reshape(108, 92)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(label_array)\n",
    "n = 0\n",
    "nozerolabel = []\n",
    "# print(label_array.shape[0])\n",
    "# print(label_array.shape[1])\n",
    "for i in range(label_array.shape[0]):\n",
    "    for j in range(label_array.shape[1]):\n",
    "        if label_array[i][j] == 0:\n",
    "             continue\n",
    "        else:\n",
    "            n += 1\n",
    "            nozerolabel.append(label_array[i][j])\n",
    "print(n)\n",
    "print(nozerolabel)\n",
    "print(len(nozerolabel))\n",
    "np.save('./dataset(05.09)/nozerolabelindex.npy',nozerolabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('./dataset(05.09)/nozerolabelindex.npy')\n",
    "print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__数据集整合代码__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#数据集划分整合模块\n",
    "def dataset_split(data_path, labelindex, batch_size, negative_sample_ratio):\n",
    "    \n",
    "    #计算一个batch中negative_sample和positive_sample的数量\n",
    "    negative_sample_size = int(batch_size * negative_sample_ratio)\n",
    "    print('negative_sample_size:',negative_sample_size)\n",
    "    positive_sample_size = batch_size - negative_sample_size\n",
    "    print('positive_sample_size:',positive_sample_size)\n",
    "\n",
    "    #划分存储数据集（单个batch）\n",
    "    \n",
    "\n",
    "    print('labelindex:',np.load(labelindex))\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_path = './dataset(05.09)/'\n",
    "    labelindex = './dataset(05.09)/nozerolabelindex.npy'\n",
    "    test = dataset_split(data_path, labelindex, 50, 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "batch_size = 50\n",
    "\n",
    "possive_sample_size = int(batch_size * 0.5)\n",
    "negative_sample_size = batch_size - possive_sample_size\n",
    "print(possive_sample_size)\n",
    "print(negative_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset(05.09)/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class Generate_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data_path = glob.glob\\\n",
    "            (os.path.join(path,'/*.npy'))  #读取data文件夹下所有.npy格式文件\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data_path[index]\n",
    "        data = np.load(data_path)      #读取输入数据\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        \n",
    "        label_path = data_path.replace('input', 'label')\n",
    "        label = np.load(label_path)    #读取标签数据\n",
    "        tensor_label = torch.from_numpy(label)\n",
    "\n",
    "        return tensor_data, tensor_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "if __name__ == '__main__':\n",
    "    dataset1 = Generate_Dataset('./dataset(positive_negative)/input/negative_input')\n",
    "    \n",
    "    # train_dataset, validate_dataset = torch.utils.data\\\n",
    "    #             .random_split(dataset, [train_size, validate_size])\n",
    "\n",
    "    # #print(\"读入数据个数为：\", len(top_dataset))\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "    # validate_loader = DataLoader(validate_dataset, batch_size=50, shuffle=True)\n",
    "    # t = 0\n",
    "    # for train, label in train_loader:\n",
    "    #     t += 1\n",
    "    #     print(train.shape)\n",
    "    #     print(label.shape)\n",
    "    # print('共有',t,'个训练集')\n",
    "    \n",
    "    # n = 0\n",
    "    # for validate, label in validate_loader:\n",
    "    #     n += 1\n",
    "    #     print(validate.shape)\n",
    "    #     print(label.shape)\n",
    "    # print('共有',n,'个训练集')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保存positive_sample__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  81   87   92   93  117  123  128  129  303  308  309  339  344  345\n",
      "  524  525  531  560  561  567  735  740  741  771  776  777  951  956\n",
      "  957  987  992  993 1172 1173 1179 1208 1209 1215 1383 1388 1389 1419\n",
      " 1424 1425 1599 1604 1605 1635 1640 1641 1820 1821 1827 1856 1857 1863\n",
      " 2024 2025 2030 2031 2037 2060 2061 2066 2067 2072 2073 2079 2247 2252\n",
      " 2253 2259 2283 2288 2289 2295 2457 2462 2463 2468 2469 2475 2493 2498\n",
      " 2499 2504 2505 2511 2673 2678 2679 2685 2709 2714 2715 2720 2721 2727\n",
      " 2895 2900 2901 2907 2931 2936 2937 2943 3111 3117 3123 3153 3326 3333\n",
      " 3338 3339 3345 3362 3374 3375 3381 3542 3549 3554 3555 3561 3578 3590\n",
      " 3591 3597 3759 3765 3771 3801 3968 3969 3986 3987 3992 3993 4004 4005\n",
      " 4022 4023 4028 4029 4190 4197 4202 4203 4209 4226 4238 4239 4245 4407\n",
      " 4413 4419 4449 4622 4625 4628 4631 4658 4661 4662 4664 4667 4668 4839\n",
      " 4844 4875 4880 5054 5055 5060 5061 5090 5091 5096 5097 5264 5270 5271\n",
      " 5300 5306 5307 5487 5492 5523 5528 5702 5703 5709 5738 5739 5745 5912\n",
      " 5918 5919 5924 5948 5954 5955 5960 6128 6134 6135 6140 6141 6164 6170\n",
      " 6171 6176 6177 6344 6350 6351 6356 6357 6380 6386 6387 6392 6393 6566\n",
      " 6602 6776 6782 6783 6788 6812 6818 6819 6824 6999 7004 7035 7040 7214\n",
      " 7215 7250 7251 7430 7431 7466 7467 7647 7652 7683 7688 7863 7899 8078\n",
      " 8079 8114 8115 8295 8300 8331 8336 8504 8505 8510 8511 8517 8540 8541\n",
      " 8546 8547 8553 8726 8727 8732 8733 8762 8763 8768 8769 8942 8943 8948\n",
      " 8949 8978 8979 8984 8985 9158 9159 9164 9165 9194 9195 9200 9201 9374\n",
      " 9375 9380 9381 9410 9411 9416 9417 9590 9591 9596 9597 9626 9627 9632\n",
      " 9633 9806 9807 9812 9813 9842 9843 9848 9849]\n",
      "81\n",
      "87\n",
      "92\n",
      "93\n",
      "117\n",
      "123\n",
      "128\n",
      "129\n",
      "303\n",
      "308\n",
      "309\n",
      "339\n",
      "344\n",
      "345\n",
      "524\n",
      "525\n",
      "531\n",
      "560\n",
      "561\n",
      "567\n",
      "735\n",
      "740\n",
      "741\n",
      "771\n",
      "776\n",
      "777\n",
      "951\n",
      "956\n",
      "957\n",
      "987\n",
      "992\n",
      "993\n",
      "1172\n",
      "1173\n",
      "1179\n",
      "1208\n",
      "1209\n",
      "1215\n",
      "1383\n",
      "1388\n",
      "1389\n",
      "1419\n",
      "1424\n",
      "1425\n",
      "1599\n",
      "1604\n",
      "1605\n",
      "1635\n",
      "1640\n",
      "1641\n",
      "1820\n",
      "1821\n",
      "1827\n",
      "1856\n",
      "1857\n",
      "1863\n",
      "2024\n",
      "2025\n",
      "2030\n",
      "2031\n",
      "2037\n",
      "2060\n",
      "2061\n",
      "2066\n",
      "2067\n",
      "2072\n",
      "2073\n",
      "2079\n",
      "2247\n",
      "2252\n",
      "2253\n",
      "2259\n",
      "2283\n",
      "2288\n",
      "2289\n",
      "2295\n",
      "2457\n",
      "2462\n",
      "2463\n",
      "2468\n",
      "2469\n",
      "2475\n",
      "2493\n",
      "2498\n",
      "2499\n",
      "2504\n",
      "2505\n",
      "2511\n",
      "2673\n",
      "2678\n",
      "2679\n",
      "2685\n",
      "2709\n",
      "2714\n",
      "2715\n",
      "2720\n",
      "2721\n",
      "2727\n",
      "2895\n",
      "2900\n",
      "2901\n",
      "2907\n",
      "2931\n",
      "2936\n",
      "2937\n",
      "2943\n",
      "3111\n",
      "3117\n",
      "3123\n",
      "3153\n",
      "3326\n",
      "3333\n",
      "3338\n",
      "3339\n",
      "3345\n",
      "3362\n",
      "3374\n",
      "3375\n",
      "3381\n",
      "3542\n",
      "3549\n",
      "3554\n",
      "3555\n",
      "3561\n",
      "3578\n",
      "3590\n",
      "3591\n",
      "3597\n",
      "3759\n",
      "3765\n",
      "3771\n",
      "3801\n",
      "3968\n",
      "3969\n",
      "3986\n",
      "3987\n",
      "3992\n",
      "3993\n",
      "4004\n",
      "4005\n",
      "4022\n",
      "4023\n",
      "4028\n",
      "4029\n",
      "4190\n",
      "4197\n",
      "4202\n",
      "4203\n",
      "4209\n",
      "4226\n",
      "4238\n",
      "4239\n",
      "4245\n",
      "4407\n",
      "4413\n",
      "4419\n",
      "4449\n",
      "4622\n",
      "4625\n",
      "4628\n",
      "4631\n",
      "4658\n",
      "4661\n",
      "4662\n",
      "4664\n",
      "4667\n",
      "4668\n",
      "4839\n",
      "4844\n",
      "4875\n",
      "4880\n",
      "5054\n",
      "5055\n",
      "5060\n",
      "5061\n",
      "5090\n",
      "5091\n",
      "5096\n",
      "5097\n",
      "5264\n",
      "5270\n",
      "5271\n",
      "5300\n",
      "5306\n",
      "5307\n",
      "5487\n",
      "5492\n",
      "5523\n",
      "5528\n",
      "5702\n",
      "5703\n",
      "5709\n",
      "5738\n",
      "5739\n",
      "5745\n",
      "5912\n",
      "5918\n",
      "5919\n",
      "5924\n",
      "5948\n",
      "5954\n",
      "5955\n",
      "5960\n",
      "6128\n",
      "6134\n",
      "6135\n",
      "6140\n",
      "6141\n",
      "6164\n",
      "6170\n",
      "6171\n",
      "6176\n",
      "6177\n",
      "6344\n",
      "6350\n",
      "6351\n",
      "6356\n",
      "6357\n",
      "6380\n",
      "6386\n",
      "6387\n",
      "6392\n",
      "6393\n",
      "6566\n",
      "6602\n",
      "6776\n",
      "6782\n",
      "6783\n",
      "6788\n",
      "6812\n",
      "6818\n",
      "6819\n",
      "6824\n",
      "6999\n",
      "7004\n",
      "7035\n",
      "7040\n",
      "7214\n",
      "7215\n",
      "7250\n",
      "7251\n",
      "7430\n",
      "7431\n",
      "7466\n",
      "7467\n",
      "7647\n",
      "7652\n",
      "7683\n",
      "7688\n",
      "7863\n",
      "7899\n",
      "8078\n",
      "8079\n",
      "8114\n",
      "8115\n",
      "8295\n",
      "8300\n",
      "8331\n",
      "8336\n",
      "8504\n",
      "8505\n",
      "8510\n",
      "8511\n",
      "8517\n",
      "8540\n",
      "8541\n",
      "8546\n",
      "8547\n",
      "8553\n",
      "8726\n",
      "8727\n",
      "8732\n",
      "8733\n",
      "8762\n",
      "8763\n",
      "8768\n",
      "8769\n",
      "8942\n",
      "8943\n",
      "8948\n",
      "8949\n",
      "8978\n",
      "8979\n",
      "8984\n",
      "8985\n",
      "9158\n",
      "9159\n",
      "9164\n",
      "9165\n",
      "9194\n",
      "9195\n",
      "9200\n",
      "9201\n",
      "9374\n",
      "9375\n",
      "9380\n",
      "9381\n",
      "9410\n",
      "9411\n",
      "9416\n",
      "9417\n",
      "9590\n",
      "9591\n",
      "9596\n",
      "9597\n",
      "9626\n",
      "9627\n",
      "9632\n",
      "9633\n",
      "9806\n",
      "9807\n",
      "9812\n",
      "9813\n",
      "9842\n",
      "9843\n",
      "9848\n",
      "9849\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "dataindex = np.array(np.load('./dataset(05.09)/nozerolabelindex.npy'))\n",
    "print(dataindex)\n",
    "dataaddr = './dataset(05.09)/input/'\n",
    "inputsaveaddr = './dataset(positive_negative)/input/'\n",
    "\n",
    "#保存positive_sample\n",
    "for i in range(len(dataindex)):\n",
    "    # print(i)\n",
    "    index = dataindex[i]\n",
    "    print(index)\n",
    "    inputdata = np.load(os.path.join(dataaddr, str(index)+'.npy'))\n",
    "    np.save(os.path.join(inputsaveaddr,'positive_input/'+str(index)+'.npy'),inputdata)\n",
    "\n",
    "    labeladdr = dataaddr.replace('input/','label/')\n",
    "    labeldata = np.load(os.path.join(labeladdr, str(index)+'.npy'))\n",
    "    labelsaveaddr = inputsaveaddr.replace('input/','label/')\n",
    "    np.save(os.path.join(labelsaveaddr,'positive_label/'+str(index)+'.npy'),labeldata)\n",
    "\n",
    "    #保存negative_sample\n",
    "    negativesample_index = np.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__保存negative_sample__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  81   87   92   93  117  123  128  129  303  308  309  339  344  345\n",
      "  524  525  531  560  561  567  735  740  741  771  776  777  951  956\n",
      "  957  987  992  993 1172 1173 1179 1208 1209 1215 1383 1388 1389 1419\n",
      " 1424 1425 1599 1604 1605 1635 1640 1641 1820 1821 1827 1856 1857 1863\n",
      " 2024 2025 2030 2031 2037 2060 2061 2066 2067 2072 2073 2079 2247 2252\n",
      " 2253 2259 2283 2288 2289 2295 2457 2462 2463 2468 2469 2475 2493 2498\n",
      " 2499 2504 2505 2511 2673 2678 2679 2685 2709 2714 2715 2720 2721 2727\n",
      " 2895 2900 2901 2907 2931 2936 2937 2943 3111 3117 3123 3153 3326 3333\n",
      " 3338 3339 3345 3362 3374 3375 3381 3542 3549 3554 3555 3561 3578 3590\n",
      " 3591 3597 3759 3765 3771 3801 3968 3969 3986 3987 3992 3993 4004 4005\n",
      " 4022 4023 4028 4029 4190 4197 4202 4203 4209 4226 4238 4239 4245 4407\n",
      " 4413 4419 4449 4622 4625 4628 4631 4658 4661 4662 4664 4667 4668 4839\n",
      " 4844 4875 4880 5054 5055 5060 5061 5090 5091 5096 5097 5264 5270 5271\n",
      " 5300 5306 5307 5487 5492 5523 5528 5702 5703 5709 5738 5739 5745 5912\n",
      " 5918 5919 5924 5948 5954 5955 5960 6128 6134 6135 6140 6141 6164 6170\n",
      " 6171 6176 6177 6344 6350 6351 6356 6357 6380 6386 6387 6392 6393 6566\n",
      " 6602 6776 6782 6783 6788 6812 6818 6819 6824 6999 7004 7035 7040 7214\n",
      " 7215 7250 7251 7430 7431 7466 7467 7647 7652 7683 7688 7863 7899 8078\n",
      " 8079 8114 8115 8295 8300 8331 8336 8504 8505 8510 8511 8517 8540 8541\n",
      " 8546 8547 8553 8726 8727 8732 8733 8762 8763 8768 8769 8942 8943 8948\n",
      " 8949 8978 8979 8984 8985 9158 9159 9164 9165 9194 9195 9200 9201 9374\n",
      " 9375 9380 9381 9410 9411 9416 9417 9590 9591 9596 9597 9626 9627 9632\n",
      " 9633 9806 9807 9812 9813 9842 9843 9848 9849]\n",
      "一共： 9618 个negative_sample!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#生成寻址标签\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "dataindex = np.arange(0,9936)\n",
    "# print(data)\n",
    "positivedataindex = np.load('./dataset(05.09)/nozerolabelindex.npy')\n",
    "print(positivedataindex)\n",
    "for i in range(positivedataindex.shape[0]):\n",
    "    temp_value = positivedataindex[i]\n",
    "    dataindex[temp_value] = 0\n",
    "\n",
    "#保存negative_sample\n",
    "inputindex = './dataset(05.09)/input/'\n",
    "inputsaveaddr = './dataset(positive_negative)/input/'\n",
    "num = 0\n",
    "for t in range(len(dataindex)):\n",
    "    temp = dataindex[t]\n",
    "    if temp == 0:\n",
    "        continue\n",
    "    else:\n",
    "        inputdata = np.load(os.path.join(inputindex,str(temp)+'.npy'))\n",
    "        num += 1\n",
    "        np.save(os.path.join(inputsaveaddr,'negative_input/'+str(temp)+'.npy'), inputdata)\n",
    "        labelindex = inputindex.replace('input/','label/')\n",
    "        labeldata = np.load(os.path.join(labelindex,str(temp)+'.npy'))\n",
    "        labelsaveaddr = inputsaveaddr.replace('input/', 'label/')\n",
    "        np.save(os.path.join(labelsaveaddr, 'negative_label/'+str(temp)+'.npy'), labeldata)\n",
    "\n",
    "print('一共：',num, '个negative_sample!')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
