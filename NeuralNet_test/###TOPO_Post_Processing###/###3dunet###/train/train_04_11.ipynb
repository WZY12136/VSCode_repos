{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__数据导入__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class Generate_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data_path = glob.glob(os.path.join(path,'input/*.npy'))  #读取data文件夹下所有.npy格式文件\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data_path[index]\n",
    "        data = np.load(data_path)      #读取输入数据\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        \n",
    "        label_path = data_path.replace('input', 'label')\n",
    "        label = np.load(label_path)    #读取标签数据\n",
    "        tensor_label = torch.from_numpy(label)\n",
    "\n",
    "        return tensor_data, tensor_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "# if __name__ == '__main__':\n",
    "#     dataset = Generate_Dataset('../../../../Generate_dataset/Matlab_files/dataset/dataset/')\n",
    "#     train_size = int(len(dataset) * 0.9)\n",
    "#     validate_size = int(len(dataset) - train_size)\n",
    "#     train_dataset, validate_dataset = torch.utils.data.random_split(dataset, [train_size, validate_size])\n",
    "\n",
    "#     #print(\"读入数据个数为：\", len(top_dataset))\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#     validate_loader = DataLoader(validate_dataset, batch_size=1, shuffle=True)\n",
    "#     t = 0\n",
    "#     for train, label in train_loader:\n",
    "#         t += 1\n",
    "#         print(train.shape)\n",
    "#         print(label.shape)\n",
    "#     print('共有',t,'个训练集')\n",
    "    \n",
    "#     n = 0\n",
    "#     for validate, label in validate_loader:\n",
    "#         n += 1\n",
    "#         print(validate.shape)\n",
    "#         print(label.shape)\n",
    "#     print('共有',n,'个训练集')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "data_size = 45\n",
    "train_size = int(data_size * 0.9)\n",
    "print(train_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__unet3d_parts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv3d_init(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv3d_init, self).__init__()\n",
    "        self.double_conv3d_init = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels=32, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(32, out_channels, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.double_conv3d_init(input)\n",
    "\n",
    "\n",
    "class DoubleConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv3d, self).__init__()\n",
    "        self.double_conv3d = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, in_channels, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.double_conv3d(input)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down,self).__init__()\n",
    "        self.maxpool_conv3d = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2, padding=0),\n",
    "            DoubleConv3d(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.maxpool_conv3d(input)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.up3d = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        self.conv = DoubleConv3d(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, input, x):  #x是接收的从encoder传过来的融合数据\n",
    "        #print('input',input.shape)\n",
    "        #print('x',x.shape)\n",
    "        x1 = self.up3d(input)\n",
    "        #print('x1',x1.shape)\n",
    "        diffY = torch.tensor(x1.size()[3] - x.size()[3])\n",
    "        diffX = torch.tensor(x1.size()[4] - x.size()[4])#特征融合部分\n",
    "        diffZ = torch.tensor(x1.size()[2] - x.size()[2])\n",
    "        #if x1.size()[3] > x.size()[3]:\n",
    "        x3 = F.pad(x, (diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2,\n",
    "                        diffZ // 2, diffZ - diffZ // 2))\n",
    "        #print('x3',x3.shape)\n",
    "        output = torch.cat([x1, x3], dim = 1)\n",
    "        return self.conv(output)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    nn.Conv3d(in_channels, out_channels, kernel_size=(1, 1, 1)))\n",
    "    def forward(self, input):\n",
    "        return self.conv1(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__unet3d_model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self,in_channels, n_classes):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        #Encoder\n",
    "        self.inc = DoubleConv3d_init(in_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "\n",
    "        #Decoder\n",
    "        self.up1 = Up(768, 256)\n",
    "        self.up2 = Up(384, 128)\n",
    "        self.up3 = Up(192, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out1 = self.inc(input)\n",
    "        print('out1.shape:',out1.shape)\n",
    "        out2 = self.down1(out1)\n",
    "        print('out2.shape:',out2.shape)\n",
    "        out3 = self.down2(out2)\n",
    "        print('out3.shape:',out3.shape)\n",
    "        out4 = self.down3(out3)\n",
    "        print('out4.shape:',out4.shape)\n",
    "        out5 = self.up1(out4, out3)\n",
    "        print('out5.shape:',out5.shape)\n",
    "        out6 = self.up2(out5, out2)\n",
    "        print('out6.shape:',out6.shape)\n",
    "        out7 = self.up3(out6, out1)\n",
    "        print('out7.shape:',out7.shape)\n",
    "        logits = self.outc(out7)\n",
    "        print('logits.shape:',logits.shape)\n",
    "        return logits\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     net = UNet3D(in_channels =3 ,n_classes=3)\n",
    "#     print(net)\n",
    "#     para = list(net.parameters())\n",
    "#     print('parameters:', para)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "out1.shape: torch.Size([1, 64, 120, 120, 120])\n",
      "out2.shape: torch.Size([1, 128, 60, 60, 60])\n",
      "out3.shape: torch.Size([1, 256, 30, 30, 30])\n",
      "out4.shape: torch.Size([1, 512, 15, 15, 15])\n",
      "out5.shape: torch.Size([1, 256, 30, 30, 30])\n",
      "out6.shape: torch.Size([1, 128, 60, 60, 60])\n",
      "out7.shape: torch.Size([1, 64, 120, 120, 120])\n",
      "logits.shape: torch.Size([1, 1, 120, 120, 120])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m net\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     60\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../../../../Generate_dataset/Matlab_files/dataset/dataset/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 61\u001b[0m train_net(net, device, data_path)\n",
      "Cell \u001b[1;32mIn[20], line 37\u001b[0m, in \u001b[0;36mtrain_net\u001b[1;34m(net, device, data_path, epochs, batch_size, lr)\u001b[0m\n\u001b[0;32m     34\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mtrainloss\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mfloat\u001b[39m(loss),epoch)\n\u001b[0;32m     35\u001b[0m writer\u001b[39m.\u001b[39mclose()\n\u001b[1;32m---> 37\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     38\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss/train\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch_cpu\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch_cpu\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./loss')\n",
    "\n",
    "def train_net(net, device, data_path, epochs=100, batch_size=1, lr=0.00001):\n",
    "    dataset = Generate_Dataset(data_path)\n",
    "    #划分训练集和验证集\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    validate_size = int(len(dataset) - train_size)\n",
    "    train_dataset, validate_dataset = torch.utils.data.random_split(dataset, [train_size, validate_size])\n",
    "    #加载训练集和验证集\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validate_loader = DataLoader(validate_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch:',epoch)\n",
    "        net.train()\n",
    "        \n",
    "        #训练数据集\n",
    "        for data, label in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            pred = net(data)\n",
    "            loss = criterion(pred, label)\n",
    "            writer.add_scalar('trainloss',float(loss),epoch)\n",
    "            writer.close()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Loss/train', loss.item())\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "            torch.save(net.state_dict(), 'best_model.pth')\n",
    "        #验证集测试\n",
    "        for validatedata, validatelabel in validate_loader:\n",
    "            \n",
    "            validatedata = validatedata.to(device, dtype=torch.float32)\n",
    "            validatelabel = validatelabel.to(device, dtype=torch.float32)\n",
    "            validatepred = net(validatedata)\n",
    "            validateloss = criterion(validatepred, validatelabel)\n",
    "            writer.add_scalar('validateloss',float(validateloss),epoch)\n",
    "            print('Loss/validate', validateloss.item())\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = UNet3D(1, 1)\n",
    "    net.to(device=device)\n",
    "\n",
    "    data_path = \"../../../../Generate_dataset/Matlab_files/dataset/dataset/\"\n",
    "    train_net(net, device, data_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 选择设备，有cuda用cuda，没有就用cpu\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # 加载网络，图片单通道，分类为1。\n",
    "    net = UNet3D(1, 1)\n",
    "    # 将网络拷贝到deivce中\n",
    "    net.to(device=device)\n",
    "    # 加载模型参数\n",
    "    net.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    # 测试模式\n",
    "    net.eval()\n",
    "    t = 50\n",
    "    # 保存结果地址\n",
    "    save_res_path = os.path.join('./dataset/test/'+('%d_res.png'%(t)))\n",
    "    # 转为batch为1，通道为1，大小为512*512的数组\n",
    "    data = np.load('./dataset/test/topomodel_50.npy')\n",
    "    data = data.reshape(1, 1, data.shape[0], data.shape[1], data.shape[2])\n",
    "    # 转为tensor\n",
    "    data_tensor = torch.from_numpy(data)\n",
    "    # 将tensor拷贝到device中，只用cpu就是拷贝到cpu中，用cuda就是拷贝到cuda中。\n",
    "    data_tensor = data_tensor.to(device=device, dtype=torch.float32)\n",
    "    # 预测\n",
    "    pred = net(data_tensor)\n",
    "    # 提取结果\n",
    "    pred = np.array(pred.data.cpu()[0])[0]\n",
    "    print(pred)\n",
    "    # # 处理结果\n",
    "    # for i in range(pred.shape[0]):\n",
    "    #     for j in range(pred.shape[1]):\n",
    "    #         for k in range(pred.shape[2]):\n",
    "    #             if pred[i][j][k] > 0.5:\n",
    "    #                 pred[i][j][k] = 1\n",
    "    #             else:\n",
    "    #                 pred[i][j][k] = 0\n",
    "    # 保存图片\n",
    "    np.save('./dataset/test/',pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6772ea3e54c912be8400171318127616a9b64ee8b3385950b6ee172fef72396a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
