{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8911504/9912422 [00:02<00:00, 3181132.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# dataset\u001b[39;00m\n\u001b[0;32m     58\u001b[0m transforms \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mToTensor(), transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m), (\u001b[39m0.5\u001b[39m))])\n\u001b[1;32m---> 59\u001b[0m dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mMNIST(root\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdataset/\u001b[39;49m\u001b[39m\"\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransforms, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     60\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m fixed_noise \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((batch_size, noise_dim))\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:187\u001b[0m, in \u001b[0;36mMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m     download_and_extract_archive(url, download_root\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, filename\u001b[39m=\u001b[39;49mfilename, md5\u001b[39m=\u001b[39;49mmd5)\n\u001b[0;32m    188\u001b[0m \u001b[39mexcept\u001b[39;00m URLError \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    189\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to download (trying next):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[0;32m    432\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[1;32m--> 434\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[0;32m    436\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    437\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{\u001b[39;00marchive\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mextract_root\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\utils.py:155\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m# check integrity of downloaded file\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile not found or corrupted.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "# @Time    : 2022/9/25\n",
    "# @Function: 用pytorch实现一个最简单的GAN，用MNIST数据集生成新图片\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 判别器，判断一张图片来源于真实数据集的概率，输入0-1之间的数，数值越大表示数据来源于真实数据集的概率越高。\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features=img_dim, out_features=128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),  # 将输出值映射到0-1之间\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "# 生成器,用随机噪声生成图片\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),\n",
    "            # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "            # 一般二分类问题中，隐藏层用Tanh函数，输出层用Sigmod函数\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    lr = 3e-4\n",
    "    noise_dim = 50  # noise\n",
    "    image_dim = 28 * 28 * 1  # 784\n",
    "    batch_size = 32\n",
    "    num_epochs = 200\n",
    "\n",
    "    # dataset\n",
    "    transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "    dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    fixed_noise = torch.randn((batch_size, noise_dim)).to(device)\n",
    "\n",
    "    D = Discriminator(image_dim).to(device)\n",
    "    G = Generator(noise_dim, image_dim).to(device)\n",
    "    opt_disc = optim.Adam(D.parameters(), lr=lr)\n",
    "    opt_gen = optim.Adam(G.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()     # 二分类交叉熵损失函数\n",
    "\n",
    "    # 存放log的文件夹\n",
    "    log_dir = \"test-record\"\n",
    "    if (os.path.exists(log_dir)):\n",
    "        shutil.rmtree(log_dir)\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc='epochs'):\n",
    "        # GAN不需要真实label\n",
    "        for batch_idx, (img, _) in enumerate(loader):\n",
    "            img = img.view(-1, 784).to(device)\n",
    "            batch_size = img.shape[0]\n",
    "\n",
    "            # 训练判别器: max log(D(x)) + log(1 - D(G(z)))\n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            fake_img = G(noise)    # 根据随机噪声生成虚假数据\n",
    "            disc_fake = D(fake_img)    # 判别器判断生成数据为真的概率\n",
    "            # torch.zeros_like(x) 表示生成与 x 形状相同、元素全为0的张量\n",
    "            lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))    # 虚假数据与0计算损失\n",
    "            disc_real = D(img)    # 判别器判断真实数据为真的概率\n",
    "            lossD_real = criterion(disc_real, torch.ones_like(disc_real))     # 真实数据与1计算损失\n",
    "            lossD = (lossD_real + lossD_fake) / 2\n",
    "\n",
    "            D.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "\n",
    "            # 训练生成器: 在此过程中将判别器固定，min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "            output = D(fake_img)\n",
    "            lossG = criterion(output, torch.ones_like(output))\n",
    "            G.zero_grad()\n",
    "            lossG.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                # print( f\"Epoch [{epoch+1}/{num_epochs}]  Batch {batch_idx}/{len(loader)}   lossD = {lossD:.4f}, lossG = {lossG:.4f}\")\n",
    "                with torch.no_grad():\n",
    "                    # 用固定的噪声数据生成图像，以对比经过不同epoch训练后的生成器的生成能力\n",
    "                    fake_img = G(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                    real_img = img.reshape(-1, 1, 28, 28)\n",
    "\n",
    "                    # make_grid的作用是将若干幅图像拼成一幅图像\n",
    "                    img_grid_fake = torchvision.utils.make_grid(fake_img, normalize=True)\n",
    "                    img_grid_real = torchvision.utils.make_grid(real_img, normalize=True)\n",
    "\n",
    "                    writer.add_image(\"Fake Images\", img_grid_fake, global_step=epoch)\n",
    "                    writer.close()\n",
    "                    writer.add_image(\"Real Images\", img_grid_real, global_step=epoch)\n",
    "                    writer.close()\n",
    "                    writer.add_scalar(tag=\"lossD\", scalar_value=lossD, global_step=epoch)\n",
    "                    writer.close()\n",
    "                    writer.add_scalar(tag=\"lossG\", scalar_value=lossG, global_step=epoch)\n",
    "                    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义生成器模型\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# 定义判别器模型\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# 定义超参数\n",
    "input_size = 100 # 噪声向量维度\n",
    "hidden_size = 128 # 隐藏层维度\n",
    "output_size = 1 # 判别结果维度\n",
    "num_epochs = 2000\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# 初始化模型和优化器\n",
    "G = Generator(input_size, hidden_size, output_size)\n",
    "D = Discriminator(output_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=learning_rate)\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=learning_rate)\n",
    "\n",
    "# 数据集，这里使用正态分布做噪声向量\n",
    "def sample_noise(batch_size, input_size):\n",
    "    return torch.randn(batch_size, input_size)\n",
    "\n",
    "# 训练GAN模型\n",
    "for epoch in tqdm(range(num_epochs), desc='epoches'):\n",
    "    for i in range(batch_size):\n",
    "        # 训练判别器\n",
    "        D.zero_grad()\n",
    "\n",
    "        real_data = torch.ones(batch_size, output_size) # 真实数据样本标签都为1\n",
    "        fake_data = torch.zeros(batch_size, output_size) # 生成数据样本标签都为0\n",
    "\n",
    "        # 对真实数据计算损失\n",
    "        real_outputs = D(real_data)\n",
    "        d_loss_real = criterion(real_outputs, torch.ones_like(real_outputs))\n",
    "\n",
    "        # 对生成数据计算损失\n",
    "        z = sample_noise(batch_size, input_size)\n",
    "        fake_inputs = G(z)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        d_loss_fake = criterion(fake_outputs, torch.zeros_like(fake_outputs))\n",
    "\n",
    "        # 反向传播更新判别器的参数\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        G.zero_grad()\n",
    "        z = sample_noise(batch_size, input_size)\n",
    "        fake_inputs = G(z)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "\n",
    "        # 计算生成器的损失\n",
    "        g_loss = criterion(fake_outputs, torch.ones_like(fake_outputs))\n",
    "\n",
    "        # 反向传播更新生成器的参数\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    # 打印损失信息和生成图像\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "        z = sample_noise(16, input_size)\n",
    "        samples = G(z).detach().numpy()\n",
    "\n",
    "        fig, axs = plt.subplots(4, 4, figsize=(4, 4))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                axs[i, j].imshow(np.reshape(samples[i*4+j], (28, 28)), cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import  save_image\n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建文件夹\n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    out = 0.5*(x+1)\n",
    "    out = out.clamp(0,1)#Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内：\n",
    "    out = out.view(-1, 1, 28, 28)#view()函数作用是将一个多行的Tensor,拼接成一行\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #一批128个\n",
    "num_epoch = 100 #总共100批\n",
    "z_dimension = 100 #噪音维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图形的处理过程\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8864123/9912422 [00:00<00:00, 16204655.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#mnist dataset mnist数据集下载\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mnist \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mMNIST(\n\u001b[0;32m      3\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/mnist/\u001b[39;49m\u001b[39m'\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform \u001b[39m=\u001b[39;49m img_transform, download \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:187\u001b[0m, in \u001b[0;36mMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m     download_and_extract_archive(url, download_root\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, filename\u001b[39m=\u001b[39;49mfilename, md5\u001b[39m=\u001b[39;49mmd5)\n\u001b[0;32m    188\u001b[0m \u001b[39mexcept\u001b[39;00m URLError \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    189\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to download (trying next):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[0;32m    432\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[1;32m--> 434\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[0;32m    436\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    437\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{\u001b[39;00marchive\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mextract_root\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WZY\\.conda\\envs\\pytorch_cpu\\lib\\site-packages\\torchvision\\datasets\\utils.py:155\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m# check integrity of downloaded file\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile not found or corrupted.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "#mnist dataset mnist数据集下载\n",
    "mnist = datasets.MNIST(\n",
    "    root='./data/mnist/', train=True, transform = img_transform, download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader 数据载入(批次读取)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = mnist, batch_size = batch_size, shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将图片28x28展开成784，然后通过多层感知器，中间经过斜率设置为0.2的LeakyReLU激活函数，\n",
    "# 最后接sigmoid激活函数得到一个0到1之间的概率进行二分类。\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator,self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(784,256),#输入特征数为784，输出为256\n",
    "            nn.LeakyReLU(0.2),#进行非线性映射\n",
    "            nn.Linear(256,256),#进行一个线性映射\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()#也是一个激活函数，二分类问题中，\n",
    "            # sigmoid可以班实数映射到【0,1】，作为概率值，\n",
    "            # 多分类用softmax函数\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入一个100维的0～1之间的高斯分布，然后通过第一层线性变换将其映射到256维,\n",
    "# 然后通过LeakyReLU激活函数，接着进行一个线性变换，再经过一个LeakyReLU激活函数，\n",
    "# 然后经过线性变换将其变成784维，最后经过Tanh激活函数是希望生成的假的图片数据分布\n",
    "# 能够在-1～1之间。\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(100, 256), #用线性变换将输入映射到256维\n",
    "            nn.ReLU(True),       #relu激活\n",
    "            nn.Linear(256, 256), #线性变换\n",
    "            nn.ReLU(True),       #relu激活\n",
    "            nn.Linear(256, 784), #线性变换\n",
    "            nn.Tanh()            #Tanh激活使得生成数据分布在【-1,1】之间\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建对象\n",
    "D = discriminator()\n",
    "G = generator()\n",
    "if torch.cuda.is_available():\n",
    "    D = D.cuda()\n",
    "    G = G.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########判别器训练train#####################\n",
    "#分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "#此过程中，生成器参数不断更新\n",
    " \n",
    "#首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "#其次定义 优化函数,优化函数的学习率为0.0003\n",
    "criterion = nn.BCELoss() #是单目标二分类交叉熵函数\n",
    "d_optimizer = torch.optim.Adam(D.parameters(),lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(),lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################进入训练##判别器的判断过程#####################\n",
    " \n",
    "for epoch in range(num_epoch): #进行多个epoch的训练\n",
    "    for i,(img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # view()函数作用是将一个多行的Tensor,拼接成一行\n",
    "        # 第一个参数是要拼接的tensor,第二个参数是-1\n",
    "        # =============================训练判别器==================\n",
    "        img = img.view(num_img, -1)  # 将图片展开为28*28=784\n",
    "        real_img = Variable(img)  # 将tensor变成Variable放入计算图中\n",
    "        real_label = Variable(torch.ones(num_img))  # 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(num_img))  # 定义假的图片的label为0\n",
    " \n",
    "        # 计算真实图片的损失\n",
    "        real_out = D(real_img)  # 将真实图片放入判别器中\n",
    "        d_loss_real = criterion(real_out, real_label)  # 得到真实图片的loss\n",
    "        real_scores = real_out  # 得到真实图片的判别值，输出的值越接近1越好\n",
    " \n",
    "        # 计算假的图片的损失\n",
    "        z = Variable(torch.randn(num_img, z_dimension))  # 随机生成一些噪声\n",
    "        fake_img = G(z)  # 随机噪声放入生成网络中，生成一张假的图片\n",
    "        fake_out = D(fake_img)  # 判别器判断假的图片\n",
    "        d_loss_fake = criterion(fake_out, fake_label)  # 得到假的图片的loss\n",
    "        fake_scores = fake_out  # 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    " \n",
    "        # 损失函数和优化\n",
    "        d_loss = d_loss_real + d_loss_fake #损失包括判真损失和判假损失\n",
    "        d_optimizer.zero_grad()  # 在反向传播之前，先将梯度归0\n",
    "        d_loss.backward()  # 将误差反向传播\n",
    "        d_optimizer.step()  # 更新参数\n",
    " \n",
    "        # ==================训练生成器============================\n",
    "        ################################生成网络的训练###############################\n",
    "        # 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "        # 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "        # 反向传播更新的参数是生成网络里面的参数，\n",
    "        # 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的\n",
    "        # 这样就达到了对抗的目的\n",
    " \n",
    "        # 计算假的图片的损失\n",
    " \n",
    "        z = Variable(torch.randn(num_img, z_dimension))  # 得到随机噪声\n",
    "        fake_img = G(z) #随机噪声输入到生成器中，得到一副假的图片\n",
    "        output = D(fake_img)  # 经过判别器得到的结果\n",
    "        g_loss = criterion(output, real_label)  # 得到的假的图片与真实的图片的label的loss\n",
    " \n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()  # 梯度归0\n",
    "        g_loss.backward()  # 进行反向传播\n",
    "        g_optimizer.step()  # .step()一般用在反向传播后面,用于更新生成网络的参数\n",
    " \n",
    "        #打印中间的损失\n",
    "        if (i+1)%100 == 0:\n",
    "            print('Epoch[{}/{}],d_loss:{:.6f},g_loss:{:.6f} '\n",
    "                  'D real: {:.6f},D fake: {:.6f}'.format(\n",
    "                epoch,num_epoch,d_loss.item(),g_loss.item(),\n",
    "                real_scores.data.mean(),fake_scores.data.mean()  #打印的是真实图片的损失均值\n",
    "            ))\n",
    " \n",
    "        if epoch == 0:\n",
    "            real_images=to_img(real_img.cpu().data)\n",
    "            save_image(real_images, './img/real_images.png')\n",
    " \n",
    "        fake_images = to_img(real_img.cpu().data)\n",
    "        save_image(fake_images, './img/fake_images-{}.png'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(),'./generator.pth')\n",
    "torch.save(D.state_dict(),'./discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 15:05:11,996 - __main__ - INFO - This is a log info\n",
      "2023-06-25 15:05:11,996 - __main__ - WARNING - Warning exists\n",
      "2023-06-25 15:05:11,997 - __main__ - INFO - Finish\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info('This is a log info')\n",
    "logger.debug('Debugging')\n",
    "logger.warning('Warning exists')\n",
    "logger.info('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
