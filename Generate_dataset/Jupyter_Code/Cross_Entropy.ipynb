{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CrossEntropyLoss详解__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      " tensor([[ 0.6522,  0.8080,  0.2059,  0.3446, -0.2827],\n",
      "        [-1.1521, -0.6535, -0.3348, -1.6790,  1.5831],\n",
      "        [ 1.2938, -1.3619,  0.3224,  0.2244, -0.2479],\n",
      "        [-0.3655,  0.6795,  1.2152,  1.8519, -0.2604],\n",
      "        [ 0.9388, -0.2316, -0.8106, -1.9803, -1.1706]])\n",
      "one_hot:\n",
      " tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "softmax:\n",
      " tensor([[0.2541, 0.2969, 0.1626, 0.1868, 0.0997],\n",
      "        [0.0478, 0.0787, 0.1083, 0.0282, 0.7370],\n",
      "        [0.4985, 0.0350, 0.1887, 0.1711, 0.1067],\n",
      "        [0.0526, 0.1497, 0.2558, 0.4834, 0.0585],\n",
      "        [0.6026, 0.1870, 0.1048, 0.0325, 0.0731]])\n",
      "logsoftmax:\n",
      " tensor([[-1.3702, -1.2145, -1.8166, -1.6779, -2.3052],\n",
      "        [-3.0404, -2.5418, -2.2232, -3.5673, -0.3052],\n",
      "        [-0.6962, -3.3519, -1.6675, -1.7656, -2.2379],\n",
      "        [-2.9442, -1.8992, -1.3635, -0.7268, -2.8392],\n",
      "        [-0.5065, -1.6769, -2.2558, -3.4255, -2.6158]])\n",
      "one_hot*logsoftmax:\n",
      " tensor([[-1.3702, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -2.2232, -0.0000, -0.0000],\n",
      "        [-0.0000, -3.3519, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.7268, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, -2.6158]])\n",
      "nllloss:\n",
      " tensor(2.0576)\n",
      "loss:\n",
      " tensor(2.0576)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#生成神经网络output，一行对应一个样本，一列对应该样本属于该列类的预测概率\n",
    "output = torch.randn(5, 5)\n",
    "print('output:\\n',output)\n",
    "\n",
    "#生成5个样本的标签，并转换为One-Hot编码\n",
    "target = torch.tensor([0, 2, 1, 3, 4])\n",
    "one_hot = F.one_hot(target).float()\n",
    "print('one_hot:\\n',one_hot)\n",
    "\n",
    "#softmax层运算，每个通道每个像素点的值转换为预测概率值\n",
    "softmax = torch.exp(output)/torch.sum(torch.exp(output),dim=1).reshape(-1, 1)\n",
    "print('softmax:\\n',softmax)\n",
    "\n",
    "#对数运算，保证数值稳定性和overflaw、underflaw\n",
    "logsoftmax = torch.log(softmax)\n",
    "print('logsoftmax:\\n',logsoftmax)\n",
    "\n",
    "#按照label标号为1的像素点位置读取logsoftmax，计算损失函数值\n",
    "nllloss = -torch.sum(one_hot*logsoftmax)/target.shape[0]\n",
    "print('one_hot*logsoftmax:\\n',one_hot*logsoftmax)\n",
    "print('nllloss:\\n',nllloss)\n",
    "\n",
    "#直接使用封装好的CrossEntropyLoss计算损失函数值\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "value = loss(output, target)\n",
    "print('loss:\\n',value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__咽喉反流CB_Loss__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "def cb_loss(y_pred, y_true, temp, beta, confusion):\n",
    "    confusion_ = [torch.sum(temp == i) for i in range(8)]   #统计一张label中每个类别的像素点\n",
    "\n",
    "    weight = []\n",
    "    weight_dice = []\n",
    "    for i, n in zip(confusion_, confusion):\n",
    "        if i == 0:\n",
    "            weight.append(0)\n",
    "            weight_dice.append(1)\n",
    "        else:\n",
    "            weight_dice.append(1)\n",
    "            weight.append(((1.0 - beta) / (1.0 - math.pow(beta, n))))\n",
    "    \n",
    "    \n",
    "    weight = torch.FloatTensor(weight)\n",
    "    weight_dice = torch.FloatTensor(weight_dice)\n",
    "    weight = weight.to(y_pred.device)\n",
    "    weight_dice = weight_dice.to(y_pred.device)\n",
    "\n",
    "\n",
    "    criterion_train = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    loss = criterion_train(y_pred.float(), temp.float())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CB_Loss__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def cb_loss(y_pred, y_true, beta, confusion):\n",
    "    weight = [((1.0 - beta) / (1.0 - math.pow(beta, i))) for i in confusion]\n",
    "    criterion_train = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(weight))\n",
    "    loss = criterion_train(y_pred.float(), y_true.long())\n",
    "    return loss\n",
    "\n",
    "def train_for_cb_loss(model, optimizer)\n",
    "    cls = []\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \") #delimiter-定界符\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
