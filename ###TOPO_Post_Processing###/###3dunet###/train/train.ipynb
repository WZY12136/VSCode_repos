{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataLoader__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generate_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data_path = glob.glob(os.path.join(path,'input/*.npy'))  #读取data文件夹下所有.npy格式文件\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data_path[index]\n",
    "        data = np.load(data_path)      #读取输入数据\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        \n",
    "        label_path = data_path.replace('input', 'label')\n",
    "        label = np.load(label_path)    #读取标签数据\n",
    "        tensor_label = torch.from_numpy(label)\n",
    "\n",
    "        return tensor_data, tensor_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "# if __name__ == '__main__':\n",
    "#     top_dataset = Generate_Dataset('./topfiles/')\n",
    "\n",
    "#     #print(\"读入数据个数为：\", len(top_dataset))\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=top_dataset,\n",
    "#                                                batch_size=1,\n",
    "#                                                shuffle=True)\n",
    "#     for data, label in train_loader:\n",
    "#         print(data.shape)\n",
    "#         print(label.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__unet3d_parts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv3d_init(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv3d_init, self).__init__()\n",
    "        self.double_conv3d_init = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels=32, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(32, out_channels, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.double_conv3d_init(input)\n",
    "\n",
    "\n",
    "class DoubleConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv3d, self).__init__()\n",
    "        self.double_conv3d = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, in_channels, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.double_conv3d(input)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down,self).__init__()\n",
    "        self.maxpool_conv3d = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2, padding=0),\n",
    "            DoubleConv3d(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.maxpool_conv3d(input)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.up3d = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        self.conv = DoubleConv3d(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, input, x):  #x是接收的从encoder传过来的融合数据\n",
    "        #print('input',input.shape)\n",
    "        #print('x',x.shape)\n",
    "        x1 = self.up3d(input)\n",
    "        #print('x1',x1.shape)\n",
    "        diffY = torch.tensor(x1.size()[3] - x.size()[3])\n",
    "        diffX = torch.tensor(x1.size()[4] - x.size()[4])#特征融合部分\n",
    "        diffZ = torch.tensor(x1.size()[2] - x.size()[2])\n",
    "        #if x1.size()[3] > x.size()[3]:\n",
    "        x3 = F.pad(x, (diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2,\n",
    "                        diffZ // 2, diffZ - diffZ // 2))\n",
    "        #print('x3',x3.shape)\n",
    "        output = torch.cat([x1, x3], dim = 1)\n",
    "        return self.conv(output)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv,self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=(1, 1, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__unet3d_model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self,in_channels, n_classes):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        #Encoder\n",
    "        self.inc = DoubleConv3d_init(in_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "\n",
    "        #Decoder\n",
    "        self.up1 = Up(768, 256)\n",
    "        self.up2 = Up(384, 128)\n",
    "        self.up3 = Up(192, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out1 = self.inc(input)\n",
    "        print('out1.shape:',out1.shape)\n",
    "        out2 = self.down1(out1)\n",
    "        print('out2.shape:',out2.shape)\n",
    "        out3 = self.down2(out2)\n",
    "        print('out3.shape:',out3.shape)\n",
    "        out4 = self.down3(out3)\n",
    "        print('out4.shape:',out4.shape)\n",
    "        out5 = self.up1(out4, out3)\n",
    "        print('out5.shape:',out5.shape)\n",
    "        out6 = self.up2(out5, out2)\n",
    "        print('out6.shape:',out6.shape)\n",
    "        out7 = self.up3(out6, out1)\n",
    "        print('out7.shape:',out7.shape)\n",
    "        logits = self.outc(out7)\n",
    "        print('logits.shape:',logits.shape)\n",
    "        return logits\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     net = UNet3D(in_channels =3 ,n_classes=3)\n",
    "#     print(net)\n",
    "#     para = list(net.parameters())\n",
    "#     print('parameters:', para)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "out1.shape: torch.Size([1, 64, 120, 120, 120])\n",
      "out2.shape: torch.Size([1, 128, 60, 60, 60])\n",
      "out3.shape: torch.Size([1, 256, 30, 30, 30])\n",
      "out4.shape: torch.Size([1, 512, 15, 15, 15])\n",
      "out5.shape: torch.Size([1, 256, 30, 30, 30])\n",
      "out6.shape: torch.Size([1, 128, 60, 60, 60])\n",
      "out7.shape: torch.Size([1, 64, 120, 120, 120])\n",
      "logits.shape: torch.Size([1, 1, 120, 120, 120])\n",
      "Loss/train 0.7271496057510376\n",
      "out1.shape: torch.Size([1, 64, 120, 120, 120])\n",
      "out2.shape: torch.Size([1, 128, 60, 60, 60])\n",
      "out3.shape: torch.Size([1, 256, 30, 30, 30])\n",
      "out4.shape: torch.Size([1, 512, 15, 15, 15])\n",
      "out5.shape: torch.Size([1, 256, 30, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_net(net, device, data_path, epochs=40, batch_size=1, lr=0.00001):\n",
    "\n",
    "    train_dataset = Generate_Dataset(data_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch:',epoch)\n",
    "        net.train()\n",
    "        for data, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data = data.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            pred = net(data)\n",
    "            loss = criterion(pred, label)\n",
    "            print('Loss/train', loss.item())\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), 'best_model.pth')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cude' if torch.cuda.is_available() else 'cpu')\n",
    "    net = UNet3D(1, 1)\n",
    "    net.to(device=device)\n",
    "\n",
    "    data_path = \"../../../dataset/dataset/\"\n",
    "    train_net(net, device, data_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "——————————————————————————————————————————————————————————————————————————————————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataLoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generate_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data_path = glob.glob(os.path.join(path,'input/*.npy'))  #读取data文件夹下所有.npy格式文件\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data_path[index]\n",
    "        data = np.load(data_path)      #读取输入数据\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        \n",
    "        label_path = data_path.replace('input', 'label')\n",
    "        label = np.load(label_path)    #读取标签数据\n",
    "        tensor_label = torch.from_numpy(label)\n",
    "\n",
    "        return tensor_data, tensor_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "# if __name__ == '__main__':\n",
    "#     top_dataset = Generate_Dataset('./topfiles/')\n",
    "\n",
    "#     #print(\"读入数据个数为：\", len(top_dataset))\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=top_dataset,\n",
    "#                                                batch_size=1,\n",
    "#                                                shuffle=True)\n",
    "#     for data, label in train_loader:\n",
    "#         print(data.shape)\n",
    "#         print(label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__UNet__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channel=1, out_channel=2, training=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.training = training\n",
    "        self.encoder1=   nn.Conv3d(in_channel, 32, 3, stride=1, padding=1)  # b, 16, 10, 10\n",
    "        self.encoder2=   nn.Conv3d(32, 64, 3, stride=1, padding=1)  # b, 8, 3, 3\n",
    "        self.encoder3=   nn.Conv3d(64, 128, 3, stride=1, padding=1)\n",
    "        self.encoder4=   nn.Conv3d(128, 256, 3, stride=1, padding=1)\n",
    "        self.encoder5=   nn.Conv3d(256, 512, 3, stride=1, padding=1)\n",
    "        \n",
    "        self.decoder1 = nn.Conv3d(512, 256, 3, stride=1,padding=1)  # b, 16, 5, 5\n",
    "        self.decoder2 =   nn.Conv3d(256, 128, 3, stride=1, padding=1)  # b, 8, 15, 1\n",
    "        self.decoder3 =   nn.Conv3d(128, 64, 3, stride=1, padding=1)  # b, 1, 28, 28\n",
    "        self.decoder4 =   nn.Conv3d(64, 32, 3, stride=1, padding=1)\n",
    "        self.decoder5 =   nn.Conv3d(32, 2, 3, stride=1, padding=1)\n",
    "        \n",
    "        self.map4 = nn.Sequential(\n",
    "            nn.Conv3d(2, out_channel, 1, 1),\n",
    "            nn.Upsample(scale_factor=(1, 2, 2), mode='trilinear'),\n",
    "            nn.Softmax(dim =1)\n",
    "        )\n",
    "\n",
    "        # 128*128 尺度下的映射\n",
    "        self.map3 = nn.Sequential(\n",
    "            nn.Conv3d(64, out_channel, 1, 1),\n",
    "            nn.Upsample(scale_factor=(4, 8, 8), mode='trilinear'),\n",
    "            nn.Softmax(dim =1)\n",
    "        )\n",
    "\n",
    "        # 64*64 尺度下的映射\n",
    "        self.map2 = nn.Sequential(\n",
    "            nn.Conv3d(128, out_channel, 1, 1),\n",
    "            nn.Upsample(scale_factor=(8, 16, 16), mode='trilinear'),\n",
    "            nn.Softmax(dim =1)\n",
    "        )\n",
    "\n",
    "        # 32*32 尺度下的映射\n",
    "        self.map1 = nn.Sequential(\n",
    "            nn.Conv3d(256, out_channel, 1, 1),\n",
    "            nn.Upsample(scale_factor=(16, 32, 32), mode='trilinear'),\n",
    "            nn.Softmax(dim =1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = F.relu(F.max_pool3d(self.encoder1(x),2,2))\n",
    "        t1 = out\n",
    "        out = F.relu(F.max_pool3d(self.encoder2(out),2,2))\n",
    "        t2 = out\n",
    "        out = F.relu(F.max_pool3d(self.encoder3(out),2,2))\n",
    "        t3 = out\n",
    "        out = F.relu(F.max_pool3d(self.encoder4(out),2,2))\n",
    "        # t4 = out\n",
    "        # out = F.relu(F.max_pool3d(self.encoder5(out),2,2))\n",
    "        \n",
    "        # t2 = out\n",
    "        # out = F.relu(F.interpolate(self.decoder1(out),scale_factor=(2,2,2),mode ='trilinear'))\n",
    "        # print(out.shape,t4.shape)\n",
    "        output1 = self.map1(out)\n",
    "        out = F.relu(F.interpolate(self.decoder2(out),scale_factor=(2,2,2),mode ='trilinear'))\n",
    "        out = torch.add(out,t3)\n",
    "        output2 = self.map2(out)\n",
    "        print('output2:',output2.shape)\n",
    "        out = F.relu(F.interpolate(self.decoder3(out),scale_factor=(2,2,2),mode ='trilinear'))\n",
    "        print('out:',out.shape)\n",
    "        out = torch.add(out,t2)\n",
    "        output3 = self.map3(out)\n",
    "        out = F.relu(F.interpolate(self.decoder4(out),scale_factor=(2,2,2),mode ='trilinear'))\n",
    "        out = torch.add(out,t1)\n",
    "        \n",
    "        out = F.relu(F.interpolate(self.decoder5(out),scale_factor=(2,2,2),mode ='trilinear'))\n",
    "        output4 = self.map4(out)\n",
    "        # print(out.shape)\n",
    "        # print(output1.shape,output2.shape,output3.shape,output4.shape)\n",
    "        if self.training is True:\n",
    "            return output1, output2, output3, output4\n",
    "        else:\n",
    "            return output4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_net(net, device, data_path, epochs=40, batch_size=1, lr=0.00001):\n",
    "    train_dataset = Generate_Dataset(data_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print('epoch:',epoch)\n",
    "        net.train()\n",
    "        for data, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data = data.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            pred = net(data)\n",
    "            loss = criterion(pred, label)\n",
    "            print('Loss/train', loss.item())\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), 'best_model.pth')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cude' if torch.cuda.is_available() else 'cpu')\n",
    "    net = UNet3D(1, 1)\n",
    "    net.to(device=device)\n",
    "\n",
    "    data_path = \"../../../dataset/dataset/\"\n",
    "    train_net(net, device, data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 64.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "epoches= 1000\n",
    "for i in tqdm(range(epoches)):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train（UNet）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset_lits_val import Val_Dataset\n",
    "from dataset.dataset_lits_train import Train_Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "from models import UNet, ResUNet , KiUNet_min, SegNet\n",
    "\n",
    "from utils import logger, weights_init, metrics, common, loss\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "def val(model, val_loader, loss_func, n_labels):\n",
    "    model.eval()\n",
    "    val_loss = metrics.LossAverage()\n",
    "    val_dice = metrics.DiceAverage(n_labels)\n",
    "    with torch.no_grad():\n",
    "        for idx,(data, target) in tqdm(enumerate(val_loader),total=len(val_loader)):\n",
    "            data, target = data.float(), target.long()\n",
    "            target = common.to_one_hot_3d(target, n_labels)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss=loss_func(output, target)\n",
    "            \n",
    "            val_loss.update(loss.item(),data.size(0))\n",
    "            val_dice.update(output, target)\n",
    "    val_log = OrderedDict({'Val_Loss': val_loss.avg, 'Val_dice_liver': val_dice.avg[1]})\n",
    "    if n_labels==3: val_log.update({'Val_dice_tumor': val_dice.avg[2]})\n",
    "    return val_log\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_func, n_labels, alpha):\n",
    "    print(\"=======Epoch:{}=======lr:{}\".format(epoch,optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    model.train()\n",
    "    train_loss = metrics.LossAverage()\n",
    "    train_dice = metrics.DiceAverage(n_labels)\n",
    "\n",
    "    for idx, (data, target) in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "        data, target = data.float(), target.long()\n",
    "        target = common.to_one_hot_3d(target,n_labels)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss0 = loss_func(output[0], target)\n",
    "        loss1 = loss_func(output[1], target)\n",
    "        loss2 = loss_func(output[2], target)\n",
    "        loss3 = loss_func(output[3], target)\n",
    "\n",
    "        loss = loss3  +  alpha * (loss0 + loss1 + loss2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.update(loss3.item(),data.size(0))\n",
    "        train_dice.update(output[3], target)\n",
    "\n",
    "    val_log = OrderedDict({'Train_Loss': train_loss.avg, 'Train_dice_liver': train_dice.avg[1]})\n",
    "    if n_labels==3: val_log.update({'Train_dice_tumor': train_dice.avg[2]})\n",
    "    return val_log\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = config.args\n",
    "    save_path = os.path.join('./experiments', args.save)\n",
    "    if not os.path.exists(save_path): os.mkdir(save_path)\n",
    "    device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "    # data info\n",
    "    train_loader = DataLoader(dataset=Train_Dataset(args),batch_size=args.batch_size,num_workers=args.n_threads, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=Val_Dataset(args),batch_size=1,num_workers=args.n_threads, shuffle=False)\n",
    "\n",
    "    # model info\n",
    "    model = ResUNet(in_channel=1, out_channel=args.n_labels,training=True).to(device)\n",
    "\n",
    "    model.apply(weights_init.init_model)#初始化训练参数\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    common.print_network(model)\n",
    "    model = torch.nn.DataParallel(model, device_ids=args.gpu_id)  # multi-GPU\n",
    " \n",
    "    loss = loss.TverskyLoss()\n",
    "\n",
    "    log = logger.Train_Logger(save_path,\"train_log\")\n",
    "\n",
    "    best = [0,0] # 初始化最优模型的epoch和performance\n",
    "    trigger = 0  # early stop 计数器\n",
    "    alpha = 0.4 # 深监督衰减系数初始值\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        common.adjust_learning_rate(optimizer, epoch, args)\n",
    "        train_log = train(model, train_loader, optimizer, loss, args.n_labels, alpha)\n",
    "        val_log = val(model, val_loader, loss, args.n_labels)\n",
    "        log.update(epoch,train_log,val_log)\n",
    "\n",
    "        # Save checkpoint.\n",
    "        state = {'net': model.state_dict(),'optimizer':optimizer.state_dict(),'epoch': epoch}\n",
    "        torch.save(state, os.path.join(save_path, 'latest_model.pth'))\n",
    "        trigger += 1\n",
    "        if val_log['Val_dice_liver'] > best[1]:\n",
    "            print('Saving best model')\n",
    "            torch.save(state, os.path.join(save_path, 'best_model.pth'))\n",
    "            best[0] = epoch\n",
    "            best[1] = val_log['Val_dice_liver']\n",
    "            trigger = 0\n",
    "        print('Best performance at Epoch: {} | {}'.format(best[0],best[1]))\n",
    "\n",
    "        # 深监督系数衰减\n",
    "        if epoch % 30 == 0: alpha *= 0.8\n",
    "\n",
    "        # early stopping\n",
    "        if args.early_stop is not None:\n",
    "            if trigger >= args.early_stop:\n",
    "                print(\"=> early stopping\")\n",
    "                break\n",
    "        torch.cuda.empty_cache()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "from utils import logger,common\n",
    "from dataset.dataset_lits_test import Test_Datasets,to_one_hot_3d\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import numpy as np\n",
    "from models import ResUNet\n",
    "from utils.metrics import DiceAverage\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def predict_one_img(model, img_dataset, args):\n",
    "    dataloader = DataLoader(dataset=img_dataset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    model.eval()\n",
    "    test_dice = DiceAverage(args.n_labels)\n",
    "    target = to_one_hot_3d(img_dataset.label, args.n_labels)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader,total=len(dataloader)):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            # output = nn.functional.interpolate(output, scale_factor=(1//args.slice_down_scale,1//args.xy_down_scale,1//args.xy_down_scale), mode='trilinear', align_corners=False) # 空间分辨率恢复到原始size\n",
    "            img_dataset.update_result(output.detach().cpu())\n",
    "\n",
    "    pred = img_dataset.recompone_result()\n",
    "    pred = torch.argmax(pred,dim=1)\n",
    "\n",
    "    pred_img = common.to_one_hot_3d(pred,args.n_labels)\n",
    "    test_dice.update(pred_img, target)\n",
    "    \n",
    "    test_dice = OrderedDict({'Dice_liver': test_dice.avg[1]})\n",
    "    if args.n_labels==3: test_dice.update({'Dice_tumor': test_dice.avg[2]})\n",
    "    \n",
    "    pred = np.asarray(pred.numpy(),dtype='uint8')\n",
    "    if args.postprocess:\n",
    "        pass # TO DO\n",
    "    pred = sitk.GetImageFromArray(np.squeeze(pred,axis=0))\n",
    "\n",
    "    return test_dice, pred\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = config.args\n",
    "    save_path = os.path.join('./experiments', args.save)\n",
    "    device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "    # model info\n",
    "    model = ResUNet(in_channel=1, out_channel=args.n_labels,training=False).to(device)\n",
    "    model = torch.nn.DataParallel(model, device_ids=args.gpu_id)  # multi-GPU\n",
    "    ckpt = torch.load('{}/best_model.pth'.format(save_path))\n",
    "    model.load_state_dict(ckpt['net'])\n",
    "\n",
    "    test_log = logger.Test_Logger(save_path,\"test_log\")\n",
    "    # data info\n",
    "    result_save_path = '{}/result'.format(save_path)\n",
    "    if not os.path.exists(result_save_path):\n",
    "        os.mkdir(result_save_path)\n",
    "    \n",
    "    datasets = Test_Datasets(args.test_data_path,args=args)\n",
    "    for img_dataset,file_idx in datasets:\n",
    "        test_dice,pred_img = predict_one_img(model, img_dataset, args)\n",
    "        test_log.update(file_idx, test_dice)\n",
    "        sitk.WriteImage(pred_img, os.path.join(result_save_path, 'result-'+file_idx+'.gz'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00736d6b48f5446f4588683aad7793e209e6bec7179a05459ca6075966cb4b26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
